{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# K-Nearest Neighbors (KNN) Algorithm - Hands-on Implementation\n",
    "**Phase 2: From Concept to Code**\n",
    "\n",
    "Welcome to the hands-on coding session! ğŸ“\n",
    "\n",
    "In this notebook, we'll implement the KNN algorithm step by step using the student exam prediction example from our presentation.\n",
    "\n",
    "---\n",
    "\n",
    "**What you'll learn:**\n",
    "- âœ… Implement KNN from scratch\n",
    "- âœ… Calculate distances between data points\n",
    "- âœ… Find K nearest neighbors\n",
    "- âœ… Make predictions using majority voting\n",
    "- âœ… Compare with scikit-learn implementation\n",
    "- âœ… Visualize results and analyze performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# K-NEAREST NEIGHBORS (KNN) - HANDS-ON IMPLEMENTATION\n",
    "# Phase 2: From Concept to Code\n",
    "# ====================================================================\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ğŸ“ Welcome to KNN Hands-on Implementation!\")\n",
    "print(\"Let's convert our student prediction concept into working code!\")\n",
    "print(\"ğŸ“š All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recap"
   },
   "source": [
    "## ğŸ“Š 1. Quick Concept Recap\n",
    "\n",
    "Before we start coding, let's quickly recap what we learned in Phase 1 (the interactive presentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "recap_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“š QUICK RECAP - What we learned in Phase 1:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"âœ… KNN finds similar examples to make predictions\")\n",
    "print(\"âœ… We calculate distance between data points\")\n",
    "print(\"âœ… We find K nearest neighbors\")\n",
    "print(\"âœ… We use majority vote to predict\")\n",
    "print(\"âœ… We tested with Alex and Sam's data\")\n",
    "print(\"\\nNow let's code this step by step! ğŸš€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset"
   },
   "source": [
    "## ğŸ—ƒï¸ 2. Creating Our Dataset\n",
    "\n",
    "Let's recreate the exact student dataset from our presentation - 12 students with their study hours, sleep hours, and exam results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_code"
   },
   "outputs": [],
   "source": [
    "# Let's recreate the exact dataset from our presentation\n",
    "print(\"ğŸ“‹ STEP 1: Creating Our Student Dataset\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Our 12 students' data from the presentation\n",
    "students_data = {\n",
    "    'Student_ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'Hours_Studied': [8, 2, 9, 1, 7, 3, 6, 2, 8, 4, 9, 1],\n",
    "    'Hours_Slept': [7, 6, 8, 5, 7, 4, 8, 3, 6, 9, 7, 8],\n",
    "    'Result': ['Pass', 'Fail', 'Pass', 'Fail', 'Pass', 'Fail', \n",
    "               'Pass', 'Fail', 'Pass', 'Fail', 'Pass', 'Fail']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(students_data)\n",
    "print(\"Our Dataset:\")\n",
    "print(df)\n",
    "\n",
    "# Convert Result to numeric for calculations (0=Fail, 1=Pass)\n",
    "df['Result_Numeric'] = df['Result'].map({'Fail': 0, 'Pass': 1})\n",
    "print(f\"\\nğŸ“Š Dataset Info:\")\n",
    "print(f\"Total students: {len(df)}\")\n",
    "print(f\"Passed: {sum(df['Result_Numeric'])} students\")\n",
    "print(f\"Failed: {len(df) - sum(df['Result_Numeric'])} students\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## ğŸ“ˆ 3. Visualizing Our Data\n",
    "\n",
    "Let's visualize our data to understand the patterns and relationships between study hours, sleep hours, and exam results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualization_code"
   },
   "outputs": [],
   "source": [
    "# Let's visualize our data to understand the patterns\n",
    "print(\"ğŸ“ˆ STEP 2: Visualizing Our Data\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Scatter plot\n",
    "colors = ['red' if result == 'Fail' else 'green' for result in df['Result']]\n",
    "ax1.scatter(df['Hours_Studied'], df['Hours_Slept'], c=colors, s=100, alpha=0.7)\n",
    "ax1.set_xlabel('Hours Studied')\n",
    "ax1.set_ylabel('Hours Slept')\n",
    "ax1.set_title('Student Performance: Study vs Sleep Hours')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add student IDs to points\n",
    "for i, row in df.iterrows():\n",
    "    ax1.annotate(f'S{row[\"Student_ID\"]}', \n",
    "                (row['Hours_Studied'], row['Hours_Slept']),\n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# Create custom legend\n",
    "import matplotlib.patches as mpatches\n",
    "red_patch = mpatches.Patch(color='red', label='Fail')\n",
    "green_patch = mpatches.Patch(color='green', label='Pass')\n",
    "ax1.legend(handles=[red_patch, green_patch])\n",
    "\n",
    "# Bar plot showing pass/fail distribution\n",
    "result_counts = df['Result'].value_counts()\n",
    "ax2.bar(result_counts.index, result_counts.values, color=['red', 'green'], alpha=0.7)\n",
    "ax2.set_title('Pass/Fail Distribution')\n",
    "ax2.set_ylabel('Number of Students')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ‘€ What patterns do you see?\")\n",
    "print(\"ğŸ¤” Can you identify clusters of similar students?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "distance"
   },
   "source": [
    "## ğŸ§® 4. Implementing Distance Calculation\n",
    "\n",
    "The core of KNN is calculating how similar (or distant) data points are from each other. We'll use the Euclidean distance formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "distance_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ§® STEP 3: Implementing Distance Calculation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def calculate_euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distance between two points\n",
    "    Formula: âˆš[(xâ‚-xâ‚‚)Â² + (yâ‚-yâ‚‚)Â²]\n",
    "    \"\"\"\n",
    "    return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "# Test with Alex's example from presentation\n",
    "alex_data = [5, 7]  # 5 hours studied, 7 hours slept\n",
    "print(f\"Alex's data: {alex_data[0]} hours studied, {alex_data[1]} hours slept\")\n",
    "print(\"\\nCalculating distances to all students:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "distances = []\n",
    "for i, row in df.iterrows():\n",
    "    student_data = [row['Hours_Studied'], row['Hours_Slept']]\n",
    "    distance = calculate_euclidean_distance(alex_data, student_data)\n",
    "    distances.append({\n",
    "        'Student_ID': row['Student_ID'],\n",
    "        'Hours_Studied': row['Hours_Studied'],\n",
    "        'Hours_Slept': row['Hours_Slept'],\n",
    "        'Result': row['Result'],\n",
    "        'Distance': round(distance, 2)\n",
    "    })\n",
    "    print(f\"Student {row['Student_ID']}: ({row['Hours_Studied']}, {row['Hours_Slept']}) -> Distance: {distance:.2f}\")\n",
    "\n",
    "# Convert to DataFrame and sort by distance\n",
    "distances_df = pd.DataFrame(distances)\n",
    "distances_df = distances_df.sort_values('Distance')\n",
    "print(\"\\nğŸ“Š Sorted by Distance (Closest First):\")\n",
    "print(distances_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neighbors"
   },
   "source": [
    "## ğŸ¯ 5. Finding K Nearest Neighbors\n",
    "\n",
    "Now let's find the K closest students to Alex and see how different K values affect our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neighbors_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ STEP 4: Finding K Nearest Neighbors\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "def find_k_nearest_neighbors(distances_df, k):\n",
    "    \"\"\"Find K nearest neighbors\"\"\"\n",
    "    return distances_df.head(k)\n",
    "\n",
    "# Let's test with different K values\n",
    "k_values = [1, 3, 5]\n",
    "\n",
    "print(f\"Alex's nearest neighbors for different K values:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\nğŸ” K = {k}:\")\n",
    "    neighbors = find_k_nearest_neighbors(distances_df, k)\n",
    "    print(neighbors[['Student_ID', 'Hours_Studied', 'Hours_Slept', 'Result', 'Distance']])\n",
    "    \n",
    "    # Count votes\n",
    "    pass_votes = sum(neighbors['Result'] == 'Pass')\n",
    "    fail_votes = sum(neighbors['Result'] == 'Fail')\n",
    "    \n",
    "    print(f\"Votes: Pass={pass_votes}, Fail={fail_votes}\")\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = 'Pass' if pass_votes > fail_votes else 'Fail'\n",
    "    confidence = max(pass_votes, fail_votes) / k * 100\n",
    "    \n",
    "    print(f\"ğŸ¯ Prediction: {prediction}\")\n",
    "    print(f\"ğŸ“Š Confidence: {confidence:.1f}%\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "implementation"
   },
   "source": [
    "## ğŸ¤– 6. Complete KNN Implementation\n",
    "\n",
    "Now let's build a complete KNN class that we can reuse for different predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "implementation_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ¤– STEP 5: Complete KNN Implementation\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "class SimpleKNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Store training data\"\"\"\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "        print(f\"âœ… Training completed with {len(X)} samples\")\n",
    "    \n",
    "    def _calculate_distance(self, point1, point2):\n",
    "        \"\"\"Calculate Euclidean distance\"\"\"\n",
    "        return np.sqrt(np.sum((point1 - point2)**2))\n",
    "    \n",
    "    def predict_single(self, x, verbose=False):\n",
    "        \"\"\"Predict single point\"\"\"\n",
    "        # Calculate distances to all training points\n",
    "        distances = []\n",
    "        for i, train_point in enumerate(self.X_train):\n",
    "            dist = self._calculate_distance(np.array(x), train_point)\n",
    "            distances.append((dist, self.y_train[i]))\n",
    "        \n",
    "        # Sort by distance and get K nearest\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        k_nearest = distances[:self.k]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"K={self.k} nearest neighbors:\")\n",
    "            for i, (dist, label) in enumerate(k_nearest):\n",
    "                print(f\"  {i+1}. Distance: {dist:.2f}, Result: {label}\")\n",
    "        \n",
    "        # Count votes\n",
    "        votes = {}\n",
    "        for _, label in k_nearest:\n",
    "            votes[label] = votes.get(label, 0) + 1\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = max(votes, key=votes.get)\n",
    "        confidence = votes[prediction] / self.k * 100\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Votes: {votes}\")\n",
    "            print(f\"Prediction: {prediction} ({confidence:.1f}% confidence)\")\n",
    "        \n",
    "        return prediction, confidence, votes\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict multiple points\"\"\"\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            pred, _, _ = self.predict_single(x)\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "\n",
    "# Test our implementation\n",
    "print(\"ğŸ§ª Testing Our KNN Implementation\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Prepare training data\n",
    "X_train = df[['Hours_Studied', 'Hours_Slept']].values\n",
    "y_train = df['Result'].values\n",
    "\n",
    "# Create and train KNN\n",
    "knn = SimpleKNN(k=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Test with Alex\n",
    "print(\"\\nğŸ‘¨â€ğŸ“ Testing with Alex (5 hours studied, 7 hours slept):\")\n",
    "alex_prediction, alex_confidence, alex_votes = knn.predict_single([5, 7], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "testing"
   },
   "source": [
    "## ğŸ§ª 7. Testing Different Students\n",
    "\n",
    "Let's test our KNN implementation with different students, including the examples from our presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "testing_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª STEP 6: Testing Different Students\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test cases from our presentation\n",
    "test_students = {\n",
    "    'Alex': [5, 7],\n",
    "    'Sam': [4, 6],  # The edge case\n",
    "    'Maya': [7, 5]  # The practice exercise\n",
    "}\n",
    "\n",
    "print(\"Testing multiple students with K=3:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "results = []\n",
    "for name, data in test_students.items():\n",
    "    print(f\"\\nğŸ“ {name}: {data[0]} hours studied, {data[1]} hours slept\")\n",
    "    prediction, confidence, votes = knn.predict_single(data, verbose=False)\n",
    "    results.append({\n",
    "        'Student': name,\n",
    "        'Hours_Studied': data[0],\n",
    "        'Hours_Slept': data[1],\n",
    "        'Prediction': prediction,\n",
    "        'Confidence': f\"{confidence:.1f}%\",\n",
    "        'Votes': str(votes)\n",
    "    })\n",
    "    print(f\"   Prediction: {prediction} ({confidence:.1f}% confidence)\")\n",
    "    print(f\"   Votes: {votes}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nğŸ“Š Summary of Predictions:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization2"
   },
   "source": [
    "## ğŸ“Š 8. Visualizing Predictions\n",
    "\n",
    "Let's create a visualization showing our training data and the predictions for new students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualization2_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š STEP 7: Visualizing Predictions\")\n",
    "print(\"=\" * 38)\n",
    "\n",
    "# Create visualization with predictions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot training data\n",
    "for i, row in df.iterrows():\n",
    "    color = 'green' if row['Result'] == 'Pass' else 'red'\n",
    "    marker = 'o'\n",
    "    ax.scatter(row['Hours_Studied'], row['Hours_Slept'], \n",
    "              c=color, s=100, alpha=0.7, marker=marker)\n",
    "    ax.annotate(f'S{row[\"Student_ID\"]}', \n",
    "                (row['Hours_Studied'], row['Hours_Slept']),\n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# Plot prediction points\n",
    "for result in results:\n",
    "    name = result['Student']\n",
    "    x, y = result['Hours_Studied'], result['Hours_Slept']\n",
    "    color = 'darkgreen' if result['Prediction'] == 'Pass' else 'darkred'\n",
    "    ax.scatter(x, y, c=color, s=200, alpha=0.9, marker='*', \n",
    "              edgecolors='black', linewidth=2)\n",
    "    ax.annotate(f'{name}\\n({result[\"Prediction\"]})', \n",
    "                (x, y), xytext=(10, -20), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.3))\n",
    "\n",
    "ax.set_xlabel('Hours Studied')\n",
    "ax.set_ylabel('Hours Slept')\n",
    "ax.set_title('KNN Predictions: Training Data vs New Students')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Create custom legend\n",
    "import matplotlib.lines as mlines\n",
    "train_fail = mlines.Line2D([], [], color='red', marker='o', linestyle='None', markersize=8, label='Training: Fail')\n",
    "train_pass = mlines.Line2D([], [], color='green', marker='o', linestyle='None', markersize=8, label='Training: Pass')\n",
    "pred_star = mlines.Line2D([], [], color='black', marker='*', linestyle='None', markersize=12, label='New Predictions')\n",
    "ax.legend(handles=[train_fail, train_pass, pred_star], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"â­ Stars represent our predictions!\")\n",
    "print(\"ğŸ”´ Red = Predicted Fail, ğŸŸ¢ Green = Predicted Pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_comparison"
   },
   "source": [
    "## ğŸ”„ 9. Comparing Different K Values\n",
    "\n",
    "Let's see how different K values affect our predictions and understand the trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_comparison_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ STEP 8: Comparing Different K Values\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Test different K values for Alex\n",
    "k_values = [1, 3, 5, 7]\n",
    "alex_data = [5, 7]\n",
    "\n",
    "print(f\"Alex's predictions with different K values:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "k_comparison = []\n",
    "for k in k_values:\n",
    "    knn_k = SimpleKNN(k=k)\n",
    "    knn_k.fit(X_train, y_train)\n",
    "    prediction, confidence, votes = knn_k.predict_single(alex_data)\n",
    "    \n",
    "    k_comparison.append({\n",
    "        'K': k,\n",
    "        'Prediction': prediction,\n",
    "        'Confidence': f\"{confidence:.1f}%\",\n",
    "        'Pass_Votes': votes.get('Pass', 0),\n",
    "        'Fail_Votes': votes.get('Fail', 0)\n",
    "    })\n",
    "    \n",
    "    print(f\"K={k}: {prediction} ({confidence:.1f}% confidence) - Votes: {votes}\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "k_comparison_df = pd.DataFrame(k_comparison)\n",
    "print(\"\\nğŸ“Š K Values Comparison:\")\n",
    "print(k_comparison_df)\n",
    "\n",
    "# Visualize K comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "x_pos = range(len(k_values))\n",
    "confidences = [float(row['Confidence'].rstrip('%')) for row in k_comparison]\n",
    "\n",
    "bars = ax.bar(x_pos, confidences, alpha=0.7, \n",
    "              color=['red' if row['Prediction'] == 'Fail' else 'green' \n",
    "                     for row in k_comparison])\n",
    "\n",
    "ax.set_xlabel('K Value')\n",
    "ax.set_ylabel('Confidence (%)')\n",
    "ax.set_title('Alex\\'s Prediction Confidence vs K Value')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'K={k}' for k in k_values])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, comp in zip(bars, k_comparison):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "            f'{comp[\"Prediction\"]}\\n{comp[\"Confidence\"]}',\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sklearn_comparison"
   },
   "source": [
    "## ğŸ†š 10. Comparing with Scikit-Learn\n",
    "\n",
    "Let's compare our implementation with the industry-standard scikit-learn library to validate our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sklearn_comparison_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ†š STEP 9: Comparing with Scikit-Learn\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Using sklearn's KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare data for sklearn\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_train)  # Convert Pass/Fail to 0/1\n",
    "\n",
    "# Create sklearn KNN\n",
    "sklearn_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "sklearn_knn.fit(X_train, y_encoded)\n",
    "\n",
    "# Test with our students\n",
    "print(\"Comparing Our Implementation vs Scikit-Learn:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_data = [[5, 7], [4, 6], [7, 5]]  # Alex, Sam, Maya\n",
    "test_names = ['Alex', 'Sam', 'Maya']\n",
    "\n",
    "comparison_results = []\n",
    "for i, (name, data) in enumerate(zip(test_names, test_data)):\n",
    "    # Our implementation\n",
    "    our_pred, our_conf, our_votes = knn.predict_single(data)\n",
    "    \n",
    "    # Sklearn implementation\n",
    "    sklearn_pred_num = sklearn_knn.predict([data])[0]\n",
    "    sklearn_pred = le.inverse_transform([sklearn_pred_num])[0]\n",
    "    sklearn_proba = sklearn_knn.predict_proba([data])[0]\n",
    "    sklearn_conf = max(sklearn_proba) * 100\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Student': name,\n",
    "        'Our_Prediction': our_pred,\n",
    "        'Our_Confidence': f\"{our_conf:.1f}%\",\n",
    "        'Sklearn_Prediction': sklearn_pred,\n",
    "        'Sklearn_Confidence': f\"{sklearn_conf:.1f}%\",\n",
    "        'Match': 'âœ…' if our_pred == sklearn_pred else 'âŒ'\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nğŸ‘¨â€ğŸ“ {name}:\")\n",
    "    print(f\"  Our KNN:     {our_pred} ({our_conf:.1f}% confidence)\")\n",
    "    print(f\"  Sklearn KNN: {sklearn_pred} ({sklearn_conf:.1f}% confidence)\")\n",
    "    print(f\"  Match: {'âœ…' if our_pred == sklearn_pred else 'âŒ'}\")\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "print(\"\\nğŸ“Š Comparison Summary:\")\n",
    "print(comparison_df)\n",
    "\n",
    "print(\"\\nğŸ¯ Great! Our implementation matches sklearn!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive"
   },
   "source": [
    "## ğŸ® 11. Interactive Exercise - Your Turn!\n",
    "\n",
    "Now it's your turn to experiment! Try different scenarios and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ® STEP 10: Your Turn - Interactive Exercise!\")\n",
    "print(\"=\" * 48)\n",
    "\n",
    "print(\"Now it's your turn to experiment!\")\n",
    "print(\"Try different scenarios and see what happens:\")\n",
    "\n",
    "def interactive_prediction(study_hours, sleep_hours, k_value):\n",
    "    \"\"\"Interactive function for students to try\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ¯ INTERACTIVE KNN PREDICTOR\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"ğŸ“š Testing student with:\")\n",
    "    print(f\"  - Study hours: {study_hours}\")\n",
    "    print(f\"  - Sleep hours: {sleep_hours}\")\n",
    "    print(f\"  - K value: {k_value}\")\n",
    "    \n",
    "    # Create KNN with chosen K\n",
    "    knn_interactive = SimpleKNN(k=k_value)\n",
    "    knn_interactive.fit(X_train, y_train)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction, confidence, votes = knn_interactive.predict_single(\n",
    "        [study_hours, sleep_hours], verbose=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Final Prediction: {prediction}\")\n",
    "    print(f\"ğŸ“Š Confidence: {confidence:.1f}%\")\n",
    "    \n",
    "    # Show where this point falls in our data\n",
    "    print(f\"\\nğŸ’¡ Analysis:\")\n",
    "    if study_hours >= 7 and sleep_hours >= 6:\n",
    "        print(\"  This student has good study and sleep habits!\")\n",
    "    elif study_hours <= 3:\n",
    "        print(\"  Low study hours - risky!\")\n",
    "    elif sleep_hours <= 4:\n",
    "        print(\"  Low sleep hours - might affect performance!\")\n",
    "    else:\n",
    "        print(\"  This is a borderline case - could go either way!\")\n",
    "    \n",
    "    return prediction, confidence\n",
    "\n",
    "# Example predictions - YOU CAN MODIFY THESE VALUES!\n",
    "print(\"\\nğŸ§ª Try these examples (or modify the values):\")\n",
    "\n",
    "# Example 1: High performer\n",
    "interactive_prediction(study_hours=9, sleep_hours=8, k_value=3)\n",
    "\n",
    "# Example 2: Struggling student\n",
    "interactive_prediction(study_hours=2, sleep_hours=4, k_value=3)\n",
    "\n",
    "# Example 3: Your custom example\n",
    "interactive_prediction(study_hours=6, sleep_hours=6, k_value=5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ¯ TRY IT YOURSELF!\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. Change the study_hours, sleep_hours, and k_value in the examples above\")\n",
    "print(\"2. Run the cell again to see different predictions\")\n",
    "print(\"3. Try extreme values like (1,1) or (10,10)\")\n",
    "print(\"4. See how different K values affect the results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "performance"
   },
   "source": [
    "## ğŸ“ˆ 12. Performance Analysis\n",
    "\n",
    "Let's analyze how well our KNN performs and understand the impact of different K values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "performance_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“ˆ STEP 11: Performance Analysis\")\n",
    "print(\"=\" * 38)\n",
    "\n",
    "# Let's analyze how well our KNN performs on the training data\n",
    "print(\"Testing KNN performance on training data:\")\n",
    "print(\"(Note: This is just for learning - normally we'd use separate test data)\")\n",
    "\n",
    "# Test with different K values\n",
    "k_values = [1, 3, 5, 7]\n",
    "performance_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn_test = SimpleKNN(k=k)\n",
    "    knn_test.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training data\n",
    "    predictions = knn_test.predict(X_train)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = sum(1 for i, pred in enumerate(predictions) if pred == y_train[i])\n",
    "    accuracy = correct / len(y_train) * 100\n",
    "    \n",
    "    performance_results.append({\n",
    "        'K': k,\n",
    "        'Correct_Predictions': correct,\n",
    "        'Total_Predictions': len(y_train),\n",
    "        'Accuracy': f\"{accuracy:.1f}%\"\n",
    "    })\n",
    "    \n",
    "    print(f\"K={k}: {correct}/{len(y_train)} correct ({accuracy:.1f}%)\")\n",
    "\n",
    "# Create performance DataFrame\n",
    "performance_df = pd.DataFrame(performance_results)\n",
    "print(\"\\nğŸ“Š Performance Summary:\")\n",
    "print(performance_df)\n",
    "\n",
    "# Visualize performance\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "accuracies = [float(row['Accuracy'].rstrip('%')) for row in performance_results]\n",
    "\n",
    "ax.plot(k_values, accuracies, marker='o', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('K Value')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('KNN Performance vs K Value')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xticks(k_values)\n",
    "\n",
    "# Add value labels\n",
    "for k, acc in zip(k_values, accuracies):\n",
    "    ax.annotate(f'{acc:.1f}%', (k, acc), xytext=(0, 10), \n",
    "                textcoords='offset points', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ Key Insights:\")\n",
    "print(\"- K=1 might overfit (memorizes training data)\")\n",
    "print(\"- Higher K values might be more robust\")\n",
    "print(\"- For real applications, always test on separate data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "real_dataset"
   },
   "source": [
    "## ğŸ¯ 13. Real Dataset Example\n",
    "\n",
    "Let's test our KNN on a larger, more realistic dataset to see how it performs in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "real_dataset_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ STEP 12: Real Dataset Example\")\n",
    "print(\"=\" * 38)\n",
    "\n",
    "# Let's create a larger, more realistic dataset\n",
    "np.random.seed(42)  # For reproducible results\n",
    "\n",
    "# Generate synthetic student data\n",
    "n_students = 100\n",
    "study_hours = np.random.normal(5, 2.5, n_students)  # Mean 5, std 2.5\n",
    "sleep_hours = np.random.normal(7, 1.5, n_students)  # Mean 7, std 1.5\n",
    "\n",
    "# Clip to reasonable ranges\n",
    "study_hours = np.clip(study_hours, 0, 12)\n",
    "sleep_hours = np.clip(sleep_hours, 3, 12)\n",
    "\n",
    "# Create realistic pass/fail based on study and sleep\n",
    "# Higher study hours and adequate sleep increase pass probability\n",
    "pass_probability = 0.1 + 0.7 * (study_hours / 12) + 0.2 * (sleep_hours / 12)\n",
    "pass_probability = np.clip(pass_probability, 0, 1)\n",
    "\n",
    "# Generate results based on probability\n",
    "results = np.random.binomial(1, pass_probability, n_students)\n",
    "results_text = ['Pass' if r == 1 else 'Fail' for r in results]\n",
    "\n",
    "# Create DataFrame\n",
    "large_df = pd.DataFrame({\n",
    "    'Hours_Studied': study_hours,\n",
    "    'Hours_Slept': sleep_hours,\n",
    "    'Result': results_text\n",
    "})\n",
    "\n",
    "print(f\"ğŸ“Š Generated {len(large_df)} students\")\n",
    "print(f\"Pass rate: {sum(results)/len(results)*100:.1f}%\")\n",
    "\n",
    "# Visualize the larger dataset\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Scatter plot\n",
    "colors = ['red' if r == 'Fail' else 'green' for r in large_df['Result']]\n",
    "ax1.scatter(large_df['Hours_Studied'], large_df['Hours_Slept'], \n",
    "           c=colors, alpha=0.6, s=30)\n",
    "ax1.set_xlabel('Hours Studied')\n",
    "ax1.set_ylabel('Hours Slept')\n",
    "ax1.set_title('Large Dataset: Student Performance')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution\n",
    "result_counts = large_df['Result'].value_counts()\n",
    "ax2.bar(result_counts.index, result_counts.values, \n",
    "        color=['red', 'green'], alpha=0.7)\n",
    "ax2.set_title('Pass/Fail Distribution (Large Dataset)')\n",
    "ax2.set_ylabel('Number of Students')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test KNN on larger dataset\n",
    "print(\"\\nğŸ§ª Testing KNN on larger dataset:\")\n",
    "X_large = large_df[['Hours_Studied', 'Hours_Slept']].values\n",
    "y_large = large_df['Result'].values\n",
    "\n",
    "knn_large = SimpleKNN(k=5)\n",
    "knn_large.fit(X_large, y_large)\n",
    "\n",
    "# Test with our original students\n",
    "test_cases = [\n",
    "    ('Alex', [5, 7]),\n",
    "    ('High Performer', [9, 8]),\n",
    "    ('Struggling Student', [2, 4]),\n",
    "    ('Insomniac', [8, 3])\n",
    "]\n",
    "\n",
    "print(\"\\nPredictions on larger dataset:\")\n",
    "for name, data in test_cases:\n",
    "    pred, conf, votes = knn_large.predict_single(data)\n",
    "    print(f\"{name:20} -> {pred} ({conf:.1f}% confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "takeaways"
   },
   "source": [
    "## ğŸ“ 14. Key Takeaways & Next Steps\n",
    "\n",
    "Congratulations! You've successfully implemented KNN from scratch. Let's summarize what you've learned and what to explore next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "takeaways_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“ STEP 13: Key Takeaways & Next Steps\")\n",
    "print(\"=\" * 46)\n",
    "\n",
    "print(\"ğŸ† What you've accomplished:\")\n",
    "print(\"âœ… Implemented KNN from scratch\")\n",
    "print(\"âœ… Calculated Euclidean distances\")\n",
    "print(\"âœ… Found K nearest neighbors\")\n",
    "print(\"âœ… Made predictions using majority voting\")\n",
    "print(\"âœ… Compared different K values\")\n",
    "print(\"âœ… Validated against scikit-learn\")\n",
    "print(\"âœ… Analyzed performance\")\n",
    "print(\"âœ… Worked with larger datasets\")\n",
    "\n",
    "print(\"\\nğŸ¯ Key Insights:\")\n",
    "print(\"1. ğŸ“ Distance calculation is the core of KNN\")\n",
    "print(\"2. ğŸ—³ï¸  Majority voting makes the final decision\")\n",
    "print(\"3. ğŸšï¸  K value affects prediction confidence\")\n",
    "print(\"4. ğŸ“Š Visualization helps understand the algorithm\")\n",
    "print(\"5. ğŸ”„ Testing different scenarios builds intuition\")\n",
    "\n",
    "print(\"\\nğŸš€ Next Steps:\")\n",
    "print(\"1. ğŸ“š Try KNN on different datasets\")\n",
    "print(\"2. ğŸ”§ Experiment with different distance metrics\")\n",
    "print(\"3. ğŸ¯ Learn about cross-validation\")\n",
    "print(\"4. ğŸ“ˆ Explore other ML algorithms\")\n",
    "print(\"5. ğŸ› ï¸  Build a complete ML project\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Bonus Challenges:\")\n",
    "print(\"1. Add feature scaling/normalization\")\n",
    "print(\"2. Implement weighted KNN (closer neighbors have more influence)\")\n",
    "print(\"3. Handle ties in voting\")\n",
    "print(\"4. Add more distance metrics (Manhattan, Cosine)\")\n",
    "print(\"5. Create a web interface for predictions\")\n",
    "\n",
    "print(\"\\nğŸ‰ Congratulations! You've mastered KNN implementation!\")\n",
    "print(\"\\nğŸ“ Remember: The best way to learn ML is by doing!\")\n",
    "print(\"Keep experimenting and building projects! ğŸš€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bonus"
   },
   "source": [
    "## ğŸ”§ 15. Bonus: Advanced Features (Optional)\n",
    "\n",
    "For curious students who want to explore more advanced KNN features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bonus_code"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ BONUS: Advanced KNN Features\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "class AdvancedKNN(SimpleKNN):\n",
    "    def __init__(self, k=3, distance_metric='euclidean', weights='uniform'):\n",
    "        super().__init__(k)\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weights = weights\n",
    "    \n",
    "    def _calculate_distance(self, point1, point2):\n",
    "        \"\"\"Calculate distance using different metrics\"\"\"\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((point1 - point2)**2))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(point1 - point2))\n",
    "        elif self.distance_metric == 'chebyshev':\n",
    "            return np.max(np.abs(point1 - point2))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "    \n",
    "    def predict_single(self, x, verbose=False):\n",
    "        \"\"\"Advanced prediction with weighted voting\"\"\"\n",
    "        # Calculate distances\n",
    "        distances = []\n",
    "        for i, train_point in enumerate(self.X_train):\n",
    "            dist = self._calculate_distance(np.array(x), train_point)\n",
    "            distances.append((dist, self.y_train[i]))\n",
    "        \n",
    "        # Sort and get K nearest\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        k_nearest = distances[:self.k]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Using {self.distance_metric} distance, K={self.k}\")\n",
    "            for i, (dist, label) in enumerate(k_nearest):\n",
    "                print(f\"  {i+1}. Distance: {dist:.2f}, Result: {label}\")\n",
    "        \n",
    "        # Voting with weights\n",
    "        votes = {}\n",
    "        for dist, label in k_nearest:\n",
    "            if self.weights == 'uniform':\n",
    "                weight = 1\n",
    "            elif self.weights == 'distance':\n",
    "                weight = 1 / (dist + 1e-10)  # Avoid division by zero\n",
    "            else:\n",
    "                weight = 1\n",
    "            \n",
    "            votes[label] = votes.get(label, 0) + weight\n",
    "        \n",
    "        prediction = max(votes, key=votes.get)\n",
    "        total_weight = sum(votes.values())\n",
    "        confidence = votes[prediction] / total_weight * 100\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Weighted votes: {votes}\")\n",
    "            print(f\"Prediction: {prediction} ({confidence:.1f}% confidence)\")\n",
    "        \n",
    "        return prediction, confidence, votes\n",
    "\n",
    "# Test advanced features\n",
    "print(\"ğŸ§ª Testing Advanced Features:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Compare different distance metrics\n",
    "metrics = ['euclidean', 'manhattan', 'chebyshev']\n",
    "alex_data = [5, 7]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\nğŸ“ Using {metric} distance:\")\n",
    "    advanced_knn = AdvancedKNN(k=3, distance_metric=metric, weights='distance')\n",
    "    advanced_knn.fit(X_train, y_train)\n",
    "    pred, conf, votes = advanced_knn.predict_single(alex_data, verbose=True)\n",
    "\n",
    "print(\"\\nğŸ‰ You've now seen advanced KNN features!\")\n",
    "print(\"Try experimenting with different combinations!\")\n",
    "print(\"\\nğŸ’¡ Challenge: Implement your own distance metric!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## ğŸŠ Conclusion\n",
    "\n",
    "**Congratulations!** ğŸ‰ You've successfully:\n",
    "\n",
    "- âœ… **Understood** the KNN algorithm conceptually\n",
    "- âœ… **Implemented** KNN from scratch in Python\n",
    "- âœ… **Visualized** how the algorithm works\n",
    "- âœ… **Compared** with industry-standard implementations\n",
    "- âœ… **Analyzed** performance and edge cases\n",
    "- âœ… **Experimented** with real-world scenarios\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ **What's Next?**\n",
    "\n",
    "1. **Practice**: Try KNN on different datasets (iris, wine, digits)\n",
    "2. **Explore**: Learn other ML algorithms (Decision Trees, SVM, Neural Networks)\n",
    "3. **Build**: Create end-to-end ML projects\n",
    "4. **Share**: Teach others what you've learned!\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š **Resources for Further Learning**\n",
    "\n",
    "- **Scikit-learn Documentation**: [sklearn.neighbors.KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "- **Kaggle Learn**: Free micro-courses on Machine Learning\n",
    "- **Python ML Libraries**: pandas, numpy, matplotlib, seaborn\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Learning!** ğŸ“âœ¨"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}